{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1acd44e7-fb55-432c-99df-23f2295f35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain langchain_openai langsmith pandas langchain_experimental matplotlib langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24a831c8-3c95-4e38-93b5-bf55190b4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import  FAISS\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import pytz\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from time import monotonic\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Image\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from helper_functions import num_tokens_from_string, replace_t_with_space, replace_double_lines_with_one_line, split_into_chapters,\\\n",
    "analyse_metric_results, escape_quotes, text_wrap,extract_book_quotes_as_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "346a2e9d-8b88-4048-a2d8-95ab8b59e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "groq_api_key = \"\"\n",
    "\n",
    "guides_path='IICRC.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c76f2bf4-5763-4c59-b564-ac6d9709f10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "chapters = split_into_chapters(guides_path, start_page=89)\n",
    "chapters = replace_t_with_space(chapters)\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2a0fd60-4efc-4ff7-b725-8f2f82d90b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt_template = \"\"\"Write an extensive summary of the following, maintain headings as they're important:\n",
    "\n",
    "{text}\n",
    "\n",
    "SUMMARY:\"\"\"\n",
    "\n",
    "summarization_prompt = PromptTemplate(template=summarization_prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a549a0-b0f7-403d-89c2-e28891744b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chapter_summary(chapter):\n",
    "    \"\"\"\n",
    "    Creates a summary of a chapter using a large language model (LLM).\n",
    "\n",
    "    Args:\n",
    "        chapter: A Document object representing the chapter to summarize.\n",
    "\n",
    "    Returns:\n",
    "        A Document object containing the summary of the chapter.\n",
    "    \"\"\"\n",
    "\n",
    "    chapter_txt = chapter.page_content  # Extract chapter text\n",
    "    model_name = \"gpt-4o\"  # Specify LLM model\n",
    "    llm = ChatOpenAI(temperature=0, model_name=model_name)  # Create LLM instance\n",
    "    gpt_35_turbo_max_tokens = 16000  # Maximum token limit for the LLM\n",
    "    verbose = False  # Set to True for more detailed output\n",
    "\n",
    "    # Calculate number of tokens in the chapter text\n",
    "    num_tokens = num_tokens_from_string(chapter_txt, model_name)\n",
    "\n",
    "    # Choose appropriate chain type based on token count\n",
    "    if num_tokens < gpt_35_turbo_max_tokens:\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=summarization_prompt, verbose=verbose) \n",
    "    else:\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=summarization_prompt, combine_prompt=summarization_prompt, verbose=verbose)\n",
    "\n",
    "    start_time = monotonic()  # Start timer\n",
    "    doc_chapter = Document(page_content=chapter_txt)  # Create Document object for chapter\n",
    "    summary = chain.invoke([doc_chapter])  # Generate summary using the chain\n",
    "    print(f\"Chain type: {chain.__class__.__name__}\")  # Print chain type\n",
    "    print(f\"Run time: {monotonic() - start_time}\")  # Print execution time\n",
    "\n",
    "    summary = replace_double_lines_with_one_line(summary[\"output_text\"])\n",
    "    summary_text = \"\\n\".join(summary)\n",
    "\n",
    "    doc_summary = Document(page_content=summary_text, metadata=chapter.metadata)\n",
    "\n",
    "    return doc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71d45eb9-d3cc-4eed-b2ab-f8ebece91d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain type: StuffDocumentsChain\n",
      "Run time: 6.513036899000326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'chapter': 10}, page_content='### \\nChapter 10\\n: Inspections, Preliminary Determination, and Pre-Restoration Evaluations\\n\\n#### INTRODUCTION\\nIn the initial stages of a restoration project, restorers face the challenge of deciding between immediate action to remove water and start drying, and the need to identify and control hazards and contaminants. Key activities at the start of a project include information gathering, initial response, safety and health issue resolution, pre-restoration inspection, preliminary determination, pre-restoration evaluations, and work planning. The ANSI/IICRC S500 Standard provides guidelines for safely restoring water-damaged properties, emphasizing that processes may not always follow a linear progression and can vary based on project circumstances.\\n\\n#### QUALIFICATIONS\\nRestorers must be qualified through education, training, certification, and experience to perform core skills. They should only provide services they are licensed or certified to offer and should hire specialized experts when necessary. Restorers should address occupant questions within their scope of authority.\\n\\n#### DOCUMENTATION\\nRestorers should establish and follow documentation procedures to support project administration, planning, execution, and cost. Pre-existing damage should be documented and communicated to interested parties.\\n\\n#### DEFINITIONS\\nUnderstanding the category and class of water is crucial before beginning inspections. Categories of water range from Category 1 (sanitary) to Category 3 (grossly contaminated), with potential for deterioration over time. Classes of water intrusion estimate the evaporation load and are used to calculate humidity control needs.\\n\\n#### INITIAL CONTACT AND INFORMATION GATHERING\\nThe information gathering process starts with initial contact with the property owner or agent. Accurate information is crucial for effective mobilization and response. Information includes structure type, water intrusion details, contaminants, building history, and more.\\n\\n#### INITIAL RESPONSE, INSPECTION, AND PRELIMINARY DETERMINATION\\nDuring the initial response, restorers conduct site walkthroughs and interviews to gather information. Key activities include safety surveys, identifying water sources, determining water migration extent, and establishing drying goals. Safety and health hazards must be documented and addressed.\\n\\n#### PRE-RESTORATION EVALUATION\\nFollowing the preliminary determination, a pre-restoration evaluation is conducted to establish corrective actions. This evaluation informs the work plan, drying plan, safety and health plan, and identifies the need for specialized experts. Factors considered include emergency response actions, building materials, contents, HVAC systems, and below-grade spaces.\\n\\n#### PROJECT WORK PLANS\\nInformation from the pre-restoration evaluation is used to develop work plans. These plans guide the structural restoration procedures and contents evaluation.\\n\\n#### ONGOING INSPECTIONS AND MONITORING\\nOnce the project is underway, ongoing inspections and monitoring are essential. This includes recording temperature and humidity, checking moisture levels, and adjusting drying equipment as needed. Restorers should document complications and communicate with interested parties until drying goals are met.')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preliminary_inspection_chapter = [chapters[9]]\n",
    "preliminary_inspection_chapter2 = chapters[9]\n",
    "preliminary_inspection_summary = create_chapter_summary(preliminary_inspection_chapter2)\n",
    "preliminary_inspection_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a745655-0295-4b5e-a467-826ffda23765",
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_chapter = [chapters[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce72b72e-04c0-4843-a482-ffbf05f2f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_restoration_chapter(restoration_chapter):\n",
    "    \"\"\"\n",
    "    Encodes a list of chapter summaries into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        chapter_summaries: A list of Document objects representing the chapter summaries.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded chapter summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()  # Create OpenAI embeddings\n",
    "    restoration_vectorstore = FAISS.from_documents(restoration_chapter, embeddings)  # Create vector store\n",
    "    return restoration_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cf1c6a7-ab7e-4bb4-b8e4-0e2c2625bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_preliminary_inspection_chapter(preliminary_inspection_chapter):\n",
    "    \"\"\"\n",
    "    Encodes a list of chapter summaries into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        chapter_summaries: A list of Document objects representing the chapter summaries.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded chapter summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()  # Create OpenAI embeddings\n",
    "    preliminary_inspection_vectorstore = FAISS.from_documents(preliminary_inspection_chapter, embeddings)  # Create vector store\n",
    "    return preliminary_inspection_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "857731b6-5c8a-4853-aa44-8c0b9a2652c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_book(path, chunk_size=10000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9999bd92-cbae-44c2-a05f-4622fb845f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_frames(video_file, num_frames):\n",
    "    \"\"\"\n",
    "    Samples frames from a video file.\n",
    "    \n",
    "    Args:\n",
    "        video_file (str): The path to the video file.\n",
    "        num_frames (int): The number of frames to sample from the video.\n",
    "        \n",
    "    Returns:\n",
    "        List[Image]: A list of PIL Image objects sampled from the video.\n",
    "    \"\"\"\n",
    "    video = cv2.VideoCapture(video_file)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = max(total_frames // num_frames, 1)\n",
    "    frames = []\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        if i % interval == 0:\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            frames.append(pil_img)\n",
    "    video.release()\n",
    "    return frames\n",
    "    \n",
    "@tool\n",
    "def multimodal_inference(query: dict) -> str:\n",
    "    \"\"\"\n",
    "    Performs multimodal inference using LLaVA with input text and either images or videos.\n",
    "    \n",
    "    Args:\n",
    "        query (dict): A dictionary containing 'text' for the prompt and 'files', \n",
    "                      which can be images or videos.\n",
    "                      \n",
    "    Raises:\n",
    "        ValueError: If no image or video is provided in the query.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated output based on the text and visual input.\n",
    "    \"\"\"\n",
    "    text = query['text']\n",
    "    \n",
    "    if query.get('files'):\n",
    "        image_files = [msg['path'] for msg in query['files']]\n",
    "    else:\n",
    "        raise ValueError(\"You need to upload an image or video for LLaVA to work.\")\n",
    "\n",
    "    video_extensions = (\"avi\", \"mp4\", \"mov\", \"mkv\", \"flv\", \"wmv\", \"mjpeg\")\n",
    "    image_extensions = ('.blp', '.bmp', '.dib', '.bufr', '.cur', '.pcx', '.dcx', '.dds', '.ps', '.eps', '.fit', '.fits', '.fli', '.flc', '.ftc', '.ftu', '.gbr', '.gif', '.grib', '.h5', '.hdf', '.png', '.apng', '.jp2', '.j2k', '.jpc', '.jpf', '.jpx', '.j2c', '.icns', '.ico', '.im', '.iim', '.jfif', '.jpe', '.jpg', '.jpeg', '.mpg', '.mpeg', '.tif', '.tiff', '.mpo', '.msp', '.palm', '.pcd', '.pdf', '.pxr', '.pbm', '.pgm', '.ppm', '.pnm', '.pfm', '.psd', '.qoi', '.bw', '.rgb', '.rgba', '.sgi', '.ras', '.tga', '.icb', '.vda', '.vst', '.webp', '.wmf', '.emf', '.xbm', '.xpm')\n",
    "\n",
    "    if len(image_files) == 1:\n",
    "        if image_files[0].endswith(video_extensions):\n",
    "            # Process video and sample frames\n",
    "            image = sample_frames(image_files[0], 12)\n",
    "            image_tokens = \"<image>\" * 13\n",
    "            prompt = f\"<|im_start|>user {image_tokens}\\n{text}<|im_end|><|im_start|>assistant\"\n",
    "        elif image_files[0].endswith(image_extensions):\n",
    "            image = Image.open(image_files[0]).convert(\"RGB\")\n",
    "            prompt = f\"<|im_start|>user <image> The response to the query must be in very great detail \\n{text}<|im_end|><|im_start|>assistant\"\n",
    "    elif len(image_files) > 1:\n",
    "        # Process multiple images/videos\n",
    "        image_list = []\n",
    "        for img in image_files:\n",
    "            if img.endswith(image_extensions):\n",
    "                img = Image.open(img).convert(\"RGB\")\n",
    "                image_list.append(img)\n",
    "            elif img.endswith(video_extensions):\n",
    "                frames = sample_frames(img, 6)\n",
    "                image_list.extend(frames)\n",
    "\n",
    "        toks = \"<image>\" * len(image_list)\n",
    "        prompt = f\"<|im_start|>user {toks}\\n{text}<|im_end|><|im_start|>assistant\"\n",
    "        image = image_list\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "    output = multimodal_model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "    generated_output = processor.decode(output[0][2:], skip_special_tokens=True)\n",
    "    return generated_output\n",
    "\n",
    "@tool\n",
    "def categorize_class(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Categorizes the given information about building damages into a specific category (Fire, Water, or General).\n",
    "    \n",
    "    Args:\n",
    "        query (str): The description of building damage to be categorized.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the category of the damage.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following information about building damages into one of these categories: \"\n",
    "        \"Fire, Water, General. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    category = chain.invoke({\"query\": query}).content\n",
    "    return {\"category\": category}\n",
    "\n",
    "@tool\n",
    "def create_objectives(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates objectives for restoring building damages based on a specific category (Fire, Water, or General).\n",
    "    \n",
    "    Args:\n",
    "        query (str): The description of building damage to generate restoration objectives.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the objectives for restoring the damages.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Create objectives for restoring building damages categorized as: Fire, Water, General. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    objectives = chain.invoke({\"query\": query}).content\n",
    "    return {\"objectives\": objectives}\n",
    "\n",
    "@tool\n",
    "def book_lookup(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Looks up relevant content in a pre-chunked book stored in FAISS based on the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for in the book chunks.\n",
    "        \n",
    "    Returns:\n",
    "        str: The most relevant content found in the book based on the query.\n",
    "    \"\"\"\n",
    "    vector_store_path = \"chunks_vector_store\"\n",
    "    if os.path.exists(vector_store_path):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        chunks_vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        chunks_vector_store = encode_book(guides_path, chunk_size=10000, chunk_overlap=200)\n",
    "        chunks_vector_store.save_local(vector_store_path)\n",
    "\n",
    "    chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "    search_results = chunks_query_retriever.invoke(query)\n",
    "    if search_results:\n",
    "        return search_results[0].page_content  \n",
    "    else:\n",
    "        return \"No relevant content found.\"\n",
    "\n",
    "@tool\n",
    "def preliminary_chapter_lookup(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Looks up relevant content in a pre-chunked book stored in FAISS based on the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for in the book chunks.\n",
    "        \n",
    "    Returns:\n",
    "        str: The most relevant content found in the book based on the query.\n",
    "    \"\"\"\n",
    "    vector_store_path = \"preliminary_vector_store\"\n",
    "    \n",
    "    # Load or encode the vector store based on the presence of the FAISS index\n",
    "    if os.path.exists(vector_store_path):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        preliminary_inspection_vectorstore = FAISS.load_local(\n",
    "            vector_store_path, embeddings, allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        preliminary_inspection_vectorstore = encode_preliminary_inspection_chapter(preliminary_inspection_chapter)\n",
    "        preliminary_inspection_vectorstore.save_local(vector_store_path)\n",
    "\n",
    "    # Set up a retriever to fetch the most relevant chunk\n",
    "    preliminary_query_retriever = preliminary_inspection_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "    search_results = preliminary_query_retriever.invoke(query)\n",
    "    if search_results:\n",
    "        return search_results[0].page_content  \n",
    "    else:\n",
    "        return \"No relevant content found.\"\n",
    "\n",
    "        @tool\n",
    "def restoration_chapter_lookup(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Looks up relevant content in a pre-chunked book stored in FAISS based on the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for in the book chunks.\n",
    "        \n",
    "    Returns:\n",
    "        str: The most relevant content found in the book based on the query.\n",
    "    \"\"\"\n",
    "    vector_store_path = \"restoration_vector_store\"\n",
    "    \n",
    "    # Load or encode the vector store based on the presence of the FAISS index\n",
    "    if os.path.exists(vector_store_path):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        restoration_chapter_vectorstore = FAISS.load_local(\n",
    "            vector_store_path, embeddings, allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        restoration_chapter_vectorstore = encode_restoration_chapter(restoration_chapter)\n",
    "        restoration_chapter_vectorstore.save_local(vector_store_path)\n",
    "\n",
    "    # Set up a retriever to fetch the most relevant chunk\n",
    "    restoration_query_retriever = restoration_chapter_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "    search_results = restoration_query_retriever.invoke(query)\n",
    "\n",
    "    # Return the most relevant result if available\n",
    "    if search_results:\n",
    "        return search_results[0].page_content  \n",
    "    else:\n",
    "        return \"No relevant content found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcd671ce-eb5e-400a-addc-24eeb0593948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a444708e-f713-4215-be48-97c352492f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Multimodal\", \"Textual\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor overseeing the tasks of two agents: a Multimodal Agent and a Textual Agent.\"\n",
    "    \"Your responsibility is to manage their interactions based on the user's request and the progress of the restoration process.\"\n",
    "    \"Each agent will complete their tasks and provide a result along with their status.\"\n",
    "    \"\\n\\n1. **Multimodal Agent**: Analyzes visual data and gathers context about the building's damage.\"\n",
    "    \"\\n2. **Textual Agent**: Provides structured step-by-step restoration guidance based on categorized damage.\"\n",
    "    \"\\n\\nGiven the user’s request and the agents' results, determine which agent should act next.\"\n",
    "    \" Make sure all tasks are completed in sequence. When the restoration process is finished, respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[\"Multimodal\", \"Textual\", \"FINISH\"]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)\n",
    "\n",
    "def check_for_media(state):\n",
    "    if state.get(\"media_files\"):\n",
    "        return True  \n",
    "    return False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24c0a9bf-a4eb-413f-a063-295de2834649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f8afd63fac0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    media_files: str\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "# tools = [\n",
    "#     categorize_class,\n",
    "#     create_objectives,\n",
    "#     preliminary_chapter_lookup,\n",
    "#     restoration_chapter_lookup,\n",
    "#     book_lookup\n",
    "# ]\n",
    "textual_system_prompt = (\n",
    "    \"You are a Textual Agent responsible for guiding the restoration of a building based on context gathered by the Multimodal Agent.\"\n",
    "    \"\\n\\n1. **Categorization**: After receiving the visual data summary, categorize the damage into Water, Fire, or General.\"\n",
    "    \"\\n\\n2. **Preliminary Objectives**: Based on the damage category, retrieve initial inspection and restoration steps.\"\n",
    "    \" Use the preliminary_chapter_lookup tool to identify relevant tasks.\"\n",
    "    \"\\n3. **Restoration Steps**: After refining the objectives, use the restoration_chapter_lookup tool to retrieve detailed restoration steps.\"\n",
    "    \"\\n\\nGuide the user interactively by asking clarifying questions, providing step-by-step instructions,\"\n",
    "    \" and ensuring that all processes comply with standard guidelines (such as IICRC). Do not perform tasks independently.\"\n",
    "    \" Always utilize the tools available, and if no tools are available, respond with 'No tools'.\"\n",
    ")\n",
    "\n",
    "textual_agent = create_react_agent(llm, tools=[categorize_class,\n",
    "    create_objectives,\n",
    "    preliminary_chapter_lookup,\n",
    "    restoration_chapter_lookup,\n",
    "    book_lookup], state_modifier=system_prompt)\n",
    "textual_node = functools.partial(agent_node, agent=textual_agent, name=\"Textual\")\n",
    "\n",
    "multimodal_system_prompt = (\n",
    "    \"You are a Multimodal Agent tasked with analyzing visual data to assist in building restoration.\"\n",
    "    \"\\n\\n1. **Context Gathering**: Use the provided tool role to examine the provided visual inputs to assess the nature and severity of the damage.\"\n",
    "    \"\\n\\nOnce you've gathered this context, output your summary and don't do anything else.\"\n",
    ")\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "multimodal_agent = create_react_agent(llm, tools=[multimodal_inference])\n",
    "multimodal_node = functools.partial(agent_node, agent=multimodal_agent, name=\"Multimodal\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Textual\", textual_node)\n",
    "workflow.add_node(\"Multimodal\", multimodal_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82653e68-d627-41e6-96a3-8a9e2b622e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "# workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.add_conditional_edges(\"supervisor\", check_for_media, {True: \"Multimodal\", False: \"Textual\"})\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57f36ca0-435b-45d8-932f-240c5d7c238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ef1b41e-46ba-401e-8e9c-dfc17108ef96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content=\"Restoring a building with a water-damaged ceiling involves several steps to ensure safety, structural integrity, and aesthetics. Here's a general guide to help you through the process:\\n\\n1. **Identify the Source of Water Damage:**\\n   - Inspect the ceiling and roof for leaks, damaged pipes, or other sources of water intrusion.\\n   - Repair the source of water to prevent further damage.\\n\\n2. **Safety Precautions:**\\n   - Turn off electricity in the affected area to prevent electrical hazards.\\n   - Wear protective gear such as gloves and masks to avoid exposure to mold or contaminants.\\n\\n3. **Assess the Damage:**\\n   - Check for sagging, discoloration, or mold growth.\\n   - Determine if the ceiling material is salvageable or needs replacement.\\n\\n4. **Dry the Affected Area:**\\n   - Use fans, dehumidifiers, and ventilation to thoroughly dry the ceiling and surrounding areas.\\n   - Ensure that all moisture is removed to prevent mold growth.\\n\\n5. **Remove Damaged Materials:**\\n   - Carefully remove any damaged ceiling materials, such as drywall or plaster.\\n   - Dispose of any materials that are beyond repair.\\n\\n6. **Inspect for Mold:**\\n   - Look for signs of mold and clean with a mold remover if necessary.\\n   - Consider hiring a professional if mold is extensive.\\n\\n7. **Repair and Replace Materials:**\\n   - Replace damaged insulation, drywall, or plaster with new materials.\\n   - Use moisture-resistant materials if possible.\\n\\n8. **Seal and Paint:**\\n   - Apply a stain-blocking primer to prevent water stains from showing through.\\n   - Repaint the ceiling with a color that matches the existing decor.\\n\\n9. **Regular Maintenance:**\\n   - Inspect the roof and plumbing regularly to prevent future water damage.\\n   - Ensure proper ventilation in areas prone to moisture.\\n\\nIf the damage is extensive or if mold is present, it may be best to consult with a professional restoration company to ensure the repairs are done correctly and safely.\", additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content=\"Restoring a building with a water-damaged ceiling involves several crucial steps. Here's a detailed guide:\\n\\n1. **Identify the Source of Water Damage:**\\n   - Inspect thoroughly to find leaks or damaged pipes. Ensure repairs are made to stop further damage.\\n\\n2. **Safety First:**\\n   - Turn off electricity in the area to prevent hazards. Use protective gear to avoid exposure to mold and contaminants.\\n\\n3. **Assess the Damage:**\\n   - Look for sagging, discoloration, and mold. Decide if materials can be salvaged or need replacement.\\n\\n4. **Dry the Area:**\\n   - Use fans and dehumidifiers to dry the area thoroughly. Ensure all moisture is removed to prevent mold.\\n\\n5. **Remove Damaged Materials:**\\n   - Remove any irreparable materials like drywall or plaster. Dispose of them properly.\\n\\n6. **Mold Inspection:**\\n   - Check for mold and clean with appropriate solutions. Professional help might be needed for extensive mold.\\n\\n7. **Repair and Replace:**\\n   - Replace insulation and ceiling materials with new, moisture-resistant options.\\n\\n8. **Seal and Paint:**\\n   - Apply a stain-blocking primer and repaint to match existing decor.\\n\\n9. **Regular Maintenance:**\\n   - Regularly inspect roofs and plumbing, and ensure good ventilation to prevent future issues.\\n\\nIf damage is extensive or mold is present, consulting a professional restoration company is advisable for safe and effective repair.\", additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='Restoring a building with a water-damaged ceiling involves several steps to ensure safety and proper repair:\\n\\n1. **Identify the Source of Water Damage:**\\n   - Inspect the roof, plumbing, and surrounding areas to find and repair the source of the water leak.\\n\\n2. **Safety Precautions:**\\n   - Turn off electricity in the affected area to avoid electrical hazards and wear protective gear to prevent exposure to mold or contaminants.\\n\\n3. **Assess the Damage:**\\n   - Evaluate the extent of the damage, checking for structural integrity, mold growth, and discoloration.\\n\\n4. **Dry the Affected Area:**\\n   - Use fans and dehumidifiers to thoroughly dry the ceiling and surrounding areas to prevent mold growth.\\n\\n5. **Remove Damaged Materials:**\\n   - Carefully remove damaged ceiling materials, such as drywall or plaster, and dispose of them properly.\\n\\n6. **Inspect for Mold:**\\n   - Check for mold and clean with mold remover or consider professional help if mold is extensive.\\n\\n7. **Repair and Replace Materials:**\\n   - Replace damaged insulation, drywall, or plaster with new materials, preferably moisture-resistant.\\n\\n8. **Seal and Paint:**\\n   - Apply a stain-blocking primer to prevent water stains from seeping through and repaint to match existing decor.\\n\\n9. **Regular Maintenance:**\\n   - Conduct regular inspections of the roof and plumbing to prevent future water damage and ensure proper ventilation.\\n\\nIf the damage is extensive or if mold is present, consulting a professional restoration company may be necessary to ensure the repairs are conducted safely and effectively.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Textual'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content=\"It seems like you've uploaded three identical guides. If you have images or other specific details about the water damage you're dealing with, feel free to share them, and I can provide more tailored advice or assistance!\", additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='If you have any images of the water-damaged ceiling, you can upload them here. This will allow me to provide more specific advice or guidance on how to address the damage.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='It seems I need an image or video to provide detailed assistance using multimodal inference. If you have any visuals of the water-damaged ceiling, please upload them here. This will help me give more specific advice or insights based on the actual condition of the ceiling.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Textual'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='If you have any images of the water-damaged ceiling, feel free to upload them here. This will allow me to analyze the damage more accurately and provide specific guidance on how to proceed with the restoration.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='If you have any images or videos depicting the water-damaged ceiling, please upload them here. This will enable me to perform a multimodal analysis, combining visual data with textual information for more precise assistance.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content=\"It looks like I need an image or video file to assist you using multimodal inference. If you have any visuals of the water-damaged ceiling, please upload them here, and I'll provide more detailed guidance based on that information.\", additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Textual'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content=\"It seems like you've mentioned the restoration process multiple times. Is there anything specific you'd like to ask or need clarification on? If you have any images of the water-damaged ceiling, feel free to upload them for a more tailored analysis.\", additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Multimodal'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='It seems like there was a repetition of the restoration process. If you have specific questions or need further clarification on any step, feel free to ask! Additionally, if you have images of the water-damaged ceiling, you can upload them for a more detailed analysis and tailored advice.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Textual'}}\n",
      "{'Multimodal': {'messages': [HumanMessage(content='If you have any specific images or videos of the water-damaged ceiling that you need help with, please upload them here. This will allow me to analyze the visual data and provide more precise advice on how to address the damage.', additional_kwargs={}, response_metadata={}, name='Multimodal')]}}\n",
      "{'supervisor': {'next': 'Textual'}}\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(event)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1285\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"How to restore a building with water damaged ceiling\")\n",
    "        ],\n",
    "        \"media_files\": \"causes-of-structural-damage.jpg\"\n",
    "    }\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc8a98-4d94-4ca3-a9a8-7f8bf7070c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31eccda-7dfe-4c3b-ae09-cb4ea4197e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
